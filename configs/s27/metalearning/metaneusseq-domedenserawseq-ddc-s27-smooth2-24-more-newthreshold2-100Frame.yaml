name: metaneusseq-domedenseseq_meta-${dataset.scene}
tag: ''
seed: 42

defaults:
  - ../../base.yaml

dataset:
  name: domedenserawseq_meta
  subject: Subject0027
  frames: [ 1000, 1250, 1500, 1750, 2000, 2250, 2500, 2750, 3000, 3250, 3500, 3750, 4000, 4250, 4500, 4750, 5000, 5250, 5500, 5750, 6000, 6250, 6500, 6750, 7000, 7250, 7500, 7750, 8000, 8250, 8500, 8750, 9000, 9250, 9500, 9750, 10000, 10250, 10500, 10750, 11000, 11250, 11500, 11750, 12000, 12250, 12500, 12750, 13000, 13250, 13500, 13750, 14000, 14250, 14500, 14750, 15000, 15250, 15500, 15750, 16000, 16250, 16500, 16750, 17000, 17250, 17500, 17750, 18000, 18250, 18500, 18750, 19000, 19250, 19500, 19750, 20000, 20250, 20500, 20750, 21000, 21250, 21500, 21750, 22000, 22250, 22500, 22750, 23000, 23250, 23500, 23750, 24000, 24250, 24500, 24750, 25000, 25250, 25500, 25750, 26000, 26250, 26500, 26750, 27000, 27250, 27500, 27750 ]

  frames_path:
  data_dir: ${root_dir}/datas/${dataset.subject}/tight/training
  scene: ${dataset.subject}
  img_downscale: 1 # specify training image size by either img_wh or img_downscale
  near_plane: 2.0
  far_plane: 6.0
  train_split: 'train'
  val_split: 'val'
  test_split: 'test'
  deformer: 'ddc'
  cano_motion: 'template' # 'world'
  default_path: ${root_dir}/datas/ddc_configs/default.yaml
  config_path: ${root_dir}/datas/ddc_configs/s27_smooth_eg.yaml
  active_camera: []
  active_camera_all: True
  smooth: True
  smoothDQ: False
  subdiv: 0
  loose: True
  inner_steps: 24
  blur: False
  blurNum: 1
  threshold_smpl: 0.075
  threshold_ddc: 0.05
  smpl_name: "smpl_params_smplx.npz"
  smpl_gender: 'neutral'
  ddc_name: "ddc_all_smooth_less.npz"
  with_depth: False
  depth_shift: 0.0
  threshold_rigid: 0.05
  threshold_outer: 0.01
  preload: True
model:
  decay_step: 300
  grid_resolution: 256
  name: neus
  radius: 1.25
  num_samples_per_ray: 1024
  train_num_rays: 256
  max_train_num_rays: 8192
  grid_prune: true
  grid_prune_occ_thre: 0.001
  dynamic_ray_sampling: true
  batch_image_sampling: true
  randomized: true
  ray_chunk: 4096
  cos_anneal_end: 20000
  learned_background: false
  background_color: random
  variance:
    init_val: 0.3
    modulate: false
  geometry:
    name: volume-sdf
    radius: ${model.radius}
    feature_dim: 13
    grad_type: analytic
    isosurface:
      method: mc
      resolution: [256,512,256]
      chunk: 2097152
      threshold: 0.
    xyz_encoding_config:
      otype: HashGrid
      n_levels:  12 #14
      n_features_per_level: 2
      log2_hashmap_size: 19
      base_resolution: 16
      per_level_scale: 1.447269237440378
      include_xyz: true
    mlp_network_config:
      otype: VanillaMLP
      activation: ReLU
      output_activation: none
      n_neurons: 64
      n_hidden_layers: 1
      sphere_init: true
      sphere_init_radius: 0.5
      weight_norm: false

  texture:
    name: volume-radiance
    input_feature_dim: ${add:${model.geometry.feature_dim},3} # surface normal as additional input
    dir_encoding_config:
      otype: Identity
      scale: 1.0
      offset: 0.0
    mlp_network_config:
      otype: FullyFusedMLP
      activation: ReLU
      output_activation: none
      n_neurons: 64
      n_hidden_layers: 2
    color_activation: sigmoid

system:
  name: metaneusseq-system
  loss:
    lambda_rgb_huber: 10.0
    lambda_rgb_mse: 0.
    lambda_rgb_l1: 0.
    lambda_mask: 0.1
    lambda_eikonal: 0.1
    lambda_sparsity: 0.01
    lambda_distortion: 0.
    lambda_opaque: 0.
    sparsity_scale: 1.
    lambda_sdf_reg: 0

  outer_optimizer:
    name: SGD
    args:
      lr: 1.0

  inner_optimizer:
    name: Adam
    args:
      lr: 0.01
      betas: [ 0.9, 0.99 ]
      eps: 1.e-15

  warmup_steps: 100
  warmup_steps_inner: 50
  scheduler:
    name: LinearLR # linear warm-up in the first system.warmup_steps steps
    interval: step
    args:
      start_factor: 1.0 #0.01 #0.0001 -> 0.1
      end_factor: 1.0
      total_iters: ${system.warmup_steps}
#  scheduler:
#    name: SequentialLR
#    interval: step
#    milestones:
#      - ${system.warmup_steps}
#    schedulers:
#      name: LinearLR # linear warm-up in the first system.warmup_steps steps
#      args:
#        start_factor: 1.0 #0.01 #0.0001 -> 0.1
#        end_factor: 1.0
#        total_iters: ${system.warmup_steps}
#      - name: LinearLR # linear warm-up in the first system.warmup_steps steps
#        args:
#          start_factor: 1.0 #0.01 #0.0001 -> 0.1
#          end_factor: 1.0
#          total_iters: ${system.warmup_steps}
#      - name: ExponentialLR
#        args:
#          gamma: ${calc_exp_lr_decay_rate:0.1,${sub:${trainer.max_steps},${system.warmup_steps}}}

checkpoint:
  save_top_k: -1
  every_n_train_steps: 200

export:
  save_mesh: false
  chunk_size: 2097152
  export_vertex_color: True  

trainer:
  max_steps: 3000
  log_every_n_steps: 10
  num_sanity_val_steps: 0
  val_check_interval: 20
  limit_train_batches: 1.0
  limit_val_batches: 2
  enable_progress_bar: true 
  precision: 32
